{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r\"C:\\Users\\Rahul\\Desktop\\Insurance_Churn_ParticipantsData\\Train.csv\")\n",
    "test=pd.read_csv(r\"C:\\Users\\Rahul\\Desktop\\Insurance_Churn_ParticipantsData\\Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=pd.DataFrame(np.copy(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571051</td>\n",
       "      <td>0.406843</td>\n",
       "      <td>0.984523</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.124080</td>\n",
       "      <td>-0.166935</td>\n",
       "      <td>0.503892</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.721811</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476877</td>\n",
       "      <td>0.145079</td>\n",
       "      <td>-0.577529</td>\n",
       "      <td>-0.691828</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.606965</td>\n",
       "      <td>-0.447419</td>\n",
       "      <td>1.825628</td>\n",
       "      <td>-0.983062</td>\n",
       "      <td>7.177616</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.935732</td>\n",
       "      <td>-0.364653</td>\n",
       "      <td>-1.178318</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.571051   0.406843   0.984523   0.011016  -0.569351  -0.411453   \n",
       "1  -1.124080  -0.166935   0.503892  -0.322932   0.721811   0.547323   \n",
       "2   0.476877   0.145079  -0.577529  -0.691828  -0.246560  -0.411453   \n",
       "3   1.606965  -0.447419   1.825628  -0.983062   7.177616  -0.411453   \n",
       "4  -0.935732  -0.364653  -1.178318  -0.322932   0.076230  -0.411453   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0  -0.251940          0          1          1           0           0   \n",
       "1   0.182198          0          2          1           0           0   \n",
       "2  -0.251940          0          1          1           0           0   \n",
       "3  -0.251940          1          1          0           0           1   \n",
       "4  -0.251940          8          2          1           0           1   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  \n",
       "0           0           0          11           3  \n",
       "1           0           0           5           1  \n",
       "2           0           0           1           3  \n",
       "3           0           0           5           3  \n",
       "4           0           2           8           3  "
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train[train['labels']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train[train['labels']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5,x6,x7=np.array_split(x,7)\n",
    "p=list()\n",
    "l=list()\n",
    "p=[x1,x2,x3,x4,x5,x6,x7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3967"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=1\n",
    "for i in p:\n",
    "    l.append(pd.concat([i.reset_index(drop = True),y.reset_index(drop = True)],axis=0))\n",
    "    l[j-1]=l[j-1].sample(frac=1)\n",
    "    l[j-1]=l[j-1].reset_index(drop=True)\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=l[0]\n",
    "t2=l[1]\n",
    "t3=l[2]\n",
    "t4=l[3]\n",
    "t5=l[4]\n",
    "t6=l[5]\n",
    "t7=l[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'labels'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.columns=test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571051</td>\n",
       "      <td>0.406843</td>\n",
       "      <td>0.984523</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.124080</td>\n",
       "      <td>-0.166935</td>\n",
       "      <td>0.503892</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.721811</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476877</td>\n",
       "      <td>0.145079</td>\n",
       "      <td>-0.577529</td>\n",
       "      <td>-0.691828</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.606965</td>\n",
       "      <td>-0.447419</td>\n",
       "      <td>1.825628</td>\n",
       "      <td>-0.983062</td>\n",
       "      <td>7.177616</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.935732</td>\n",
       "      <td>-0.364653</td>\n",
       "      <td>-1.178318</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.571051   0.406843   0.984523   0.011016  -0.569351  -0.411453   \n",
       "1  -1.124080  -0.166935   0.503892  -0.322932   0.721811   0.547323   \n",
       "2   0.476877   0.145079  -0.577529  -0.691828  -0.246560  -0.411453   \n",
       "3   1.606965  -0.447419   1.825628  -0.983062   7.177616  -0.411453   \n",
       "4  -0.935732  -0.364653  -1.178318  -0.322932   0.076230  -0.411453   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0  -0.251940        0.0        1.0        1.0         0.0         0.0   \n",
       "1   0.182198        0.0        2.0        1.0         0.0         0.0   \n",
       "2  -0.251940        0.0        1.0        1.0         0.0         0.0   \n",
       "3  -0.251940        1.0        1.0        0.0         0.0         1.0   \n",
       "4  -0.251940        8.0        2.0        1.0         0.0         1.0   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  \n",
       "0         0.0         0.0        11.0         3.0  \n",
       "1         0.0         0.0         5.0         1.0  \n",
       "2         0.0         0.0         1.0         3.0  \n",
       "3         0.0         0.0         5.0         3.0  \n",
       "4         0.0         2.0         8.0         3.0  "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "t11=list()\n",
    "t12=list()\n",
    "for i in l:\n",
    "    label=i['labels']\n",
    "    i.drop(columns=['labels'],inplace=True)\n",
    "    test=test1\n",
    "    \n",
    "    i['Mean']=np.mean(i.iloc[:,0:6],axis=1)\n",
    "    test['Mean']=np.mean(test.iloc[:,0:6],axis=1)\n",
    "    i['Median']=np.median(i.iloc[:,0:6],axis=1)\n",
    "    test['Median']=np.median(test.iloc[:,0:6],axis=1)\n",
    "    i['Std']=np.std(i.iloc[:,0:6],axis=1)\n",
    "    test['Std']=np.std(test.iloc[:,0:6],axis=1)\n",
    "    \n",
    "    i['Mean1']=np.mean(i.iloc[:,7:],axis=1)\n",
    "    test['Mean1']=np.mean(test.iloc[:,7:],axis=1)\n",
    "    i['Median1']=np.median(i.iloc[:,7:],axis=1)\n",
    "    test['Median1']=np.median(test.iloc[:,7:],axis=1)\n",
    "    i['Std1']=np.std(i.iloc[:,7:],axis=1)\n",
    "    test['Std1']=np.std(test.iloc[:,7:],axis=1)\n",
    "    \n",
    "    mm=MinMaxScaler()\n",
    "    tr=pd.DataFrame(mm.fit_transform(i[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "    te=pd.DataFrame(mm.fit_transform(test[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "    i=pd.concat([i,tr],axis=1)\n",
    "    test=pd.concat([test,te],axis=1)\n",
    "    i.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)\n",
    "    test.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)\n",
    "    \n",
    "    \n",
    "    a=pd.get_dummies((i[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "    b=pd.get_dummies((test[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "    i=pd.concat([i,a],axis=1)\n",
    "    test=pd.concat([test,b],axis=1)\n",
    "    \n",
    "    i.drop(columns=['feature_7','feature_8','feature_9','feature_13','feature_15'],inplace=True)\n",
    "    test.drop(columns=['feature_7','feature_8','feature_9','feature_13','feature_15'],inplace=True)\n",
    "    \n",
    "    t11.append(i)\n",
    "    t12.append(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056660602385284                 0.7905218058137985\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.7859773600161714                 0.7728434535139822\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7948965703119737                 0.782057520525584\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8019198504143926                 0.7897539166180259\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8100658985243583                 0.7997414053507067\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807345529277003                 0.7956683940041451\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076317537324209                 0.7955966129604827\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8028934202546999                 0.7911331280888941\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044487119017137                 0.7927077281120841\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8065841924398623                 0.7950260344833304\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8103982211441276                 0.7996493249606089\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8094917795296811                 0.7983232783199077\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8096529365116386                 0.7982162686289928\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8075120563689392                 0.7961440107513167\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8084614244323158                 0.796948736193068\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8097976046088539                 0.7983598135609357\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8120214271275519                 0.801010130252453\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108449565393167                 0.7992933213420834\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108499569116847                 0.799241009463194\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8086122902769355                 0.796839572315292\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088920654172324                 0.7971377350967523\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8093660069463587                 0.7976768815683609\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.810428278886633                 0.79908549754489\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8101104204568427                 0.7985184014276675\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8102016575702446                 0.7985775754263756\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8084822192159972                 0.7970315716489313\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8087701487620629                 0.7973391716957674\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8091632735568453                 0.7977698180243699\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8105194370673972                 0.7994217191786175\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8101096961121218                 0.798844964573607\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8107591436973858                 0.7994365127169943\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8099346194663433                 0.7985727429874302\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8107756767186722                 0.7994256879284038\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.81181161488246                 0.8005211028667968\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8133075168211615                 0.80222233545828\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132057588212834                 0.8019698614348153\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8130298460983725                 0.8018002811158962\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.812105954698754                 0.8009226932262654\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122947862729548                 0.8011227945446694\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8123884172225592                 0.8013145124448314\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.8130227731022005                 0.8021734602400507\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8124649859943978                 0.801503874292578\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "z=list()\n",
    "q=list()\n",
    "for i in l:\n",
    "    label=i['labels']\n",
    "    i.drop(columns=['labels'],inplace=True)\n",
    "    test=test1\n",
    "    \n",
    "    i['Mean']=np.mean(i.iloc[:,0:6],axis=1)\n",
    "    test['Mean']=np.mean(test.iloc[:,0:6],axis=1)\n",
    "    i['Median']=np.median(i.iloc[:,0:6],axis=1)\n",
    "    test['Median']=np.median(test.iloc[:,0:6],axis=1)\n",
    "    i['Std']=np.std(i.iloc[:,0:6],axis=1)\n",
    "    test['Std']=np.std(test.iloc[:,0:6],axis=1)\n",
    "    \n",
    "    i['Mean1']=np.mean(i.iloc[:,7:],axis=1)\n",
    "    test['Mean1']=np.mean(test.iloc[:,7:],axis=1)\n",
    "    i['Median1']=np.median(i.iloc[:,7:],axis=1)\n",
    "    test['Median1']=np.median(test.iloc[:,7:],axis=1)\n",
    "    i['Std1']=np.std(i.iloc[:,7:],axis=1)\n",
    "    test['Std1']=np.std(test.iloc[:,7:],axis=1)\n",
    "    \n",
    "    mm=MinMaxScaler()\n",
    "    tr=pd.DataFrame(mm.fit_transform(i[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "    te=pd.DataFrame(mm.fit_transform(test[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "    i=pd.concat([i,tr],axis=1)\n",
    "    test=pd.concat([test,te],axis=1)\n",
    "    i.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)\n",
    "    test.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)\n",
    "    \n",
    "    \n",
    "    a=pd.get_dummies((i[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "    b=pd.get_dummies((test[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "    i=pd.concat([i,a],axis=1)\n",
    "    test=pd.concat([test,b],axis=1)\n",
    "    \n",
    "    i.drop(columns=['feature_7','feature_8','feature_9','feature_13','feature_15'],inplace=True)\n",
    "    test.drop(columns=['feature_7','feature_8','feature_9','feature_13','feature_15'],inplace=True)\n",
    "    \n",
    "    \n",
    "    def splitting(m, train= train, label = label, test = test, random_state = 9):\n",
    "        a = list()\n",
    "        b = list()\n",
    "        sss=StratifiedShuffleSplit(random_state= random_state,test_size=0.2,n_splits=5)\n",
    "        for tr_index, te_index in sss.split(train,label):\n",
    "            xtrain, xtest = train.loc[tr_index,:], train.loc[te_index,:]\n",
    "            ytrain, ytest = label[tr_index], label[te_index]   \n",
    "            m.fit(xtrain,ytrain)\n",
    "            p = m.predict(xtest)\n",
    "            a.append(accuracy_score(ytest,p))\n",
    "            b.append(f1_score(ytest,p))\n",
    "        #print(pd.Series(m.feature_importances_, index = train.columns).sort_values(ascending=True).plot.barh())\n",
    "          #  print(np.mean(a),'    ',np.mean(b))\n",
    "            q.append(np.mean(a))\n",
    "            z.append(np.mean(b))\n",
    "        print(np.mean(q),'               ',np.mean(z))\n",
    "  #  return(pd.DataFrame(m.predict(test)))\n",
    "\n",
    "    x=[LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier()]\n",
    "    n=1\n",
    "    while(n<=(len(l)-1)):\n",
    "        splitting(x[n-1],i,label,test,random_state=2500)\n",
    "        print(x[n-1])\n",
    "        n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.276515</td>\n",
       "      <td>-0.424429</td>\n",
       "      <td>1.344997</td>\n",
       "      <td>-0.012283</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>1.076648</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853573</td>\n",
       "      <td>0.150991</td>\n",
       "      <td>0.503892</td>\n",
       "      <td>-0.979179</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947747</td>\n",
       "      <td>-0.173832</td>\n",
       "      <td>1.825628</td>\n",
       "      <td>-0.703478</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.853573</td>\n",
       "      <td>-0.381404</td>\n",
       "      <td>0.984523</td>\n",
       "      <td>-0.039464</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.324443</td>\n",
       "      <td>1.590527</td>\n",
       "      <td>-1.178318</td>\n",
       "      <td>-0.097711</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -0.276515  -0.424429   1.344997  -0.012283   0.076230   1.076648   \n",
       "1   0.853573   0.150991   0.503892  -0.979179  -0.569351  -0.411453   \n",
       "2   0.947747  -0.173832   1.825628  -0.703478   0.076230  -0.411453   \n",
       "3   0.853573  -0.381404   0.984523  -0.039464  -0.569351  -0.411453   \n",
       "4   1.324443   1.590527  -1.178318  -0.097711  -0.246560  -0.411453   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0   0.182198          3          0          1           0           0   \n",
       "1  -0.251940          4          1          2           0           1   \n",
       "2  -0.251940          6          1          2           0           0   \n",
       "3  -0.251940          4          0          2           0           1   \n",
       "4  -0.251940          0          1          1           0           0   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  \n",
       "0           0           0          10           2  \n",
       "1           0           0           0           3  \n",
       "2           0           0           5           3  \n",
       "3           0           0           5           3  \n",
       "4           0           0           8           3  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571051</td>\n",
       "      <td>0.406843</td>\n",
       "      <td>0.984523</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.124080</td>\n",
       "      <td>-0.166935</td>\n",
       "      <td>0.503892</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.721811</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476877</td>\n",
       "      <td>0.145079</td>\n",
       "      <td>-0.577529</td>\n",
       "      <td>-0.691828</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.606965</td>\n",
       "      <td>-0.447419</td>\n",
       "      <td>1.825628</td>\n",
       "      <td>-0.983062</td>\n",
       "      <td>7.177616</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.935732</td>\n",
       "      <td>-0.364653</td>\n",
       "      <td>-1.178318</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.571051   0.406843   0.984523   0.011016  -0.569351  -0.411453   \n",
       "1  -1.124080  -0.166935   0.503892  -0.322932   0.721811   0.547323   \n",
       "2   0.476877   0.145079  -0.577529  -0.691828  -0.246560  -0.411453   \n",
       "3   1.606965  -0.447419   1.825628  -0.983062   7.177616  -0.411453   \n",
       "4  -0.935732  -0.364653  -1.178318  -0.322932   0.076230  -0.411453   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0  -0.251940          0          1          1           0           0   \n",
       "1   0.182198          0          2          1           0           0   \n",
       "2  -0.251940          0          1          1           0           0   \n",
       "3  -0.251940          1          1          0           0           1   \n",
       "4  -0.251940          8          2          1           0           1   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  \n",
       "0           0           0          11           3  \n",
       "1           0           0           5           1  \n",
       "2           0           0           1           3  \n",
       "3           0           0           5           3  \n",
       "4           0           2           8           3  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33908"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29941\n",
       "1     3967\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d1ae2abac8>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaIAAAD8CAYAAACFIdPeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHltJREFUeJzt3X+wZnddH/D3Z38kUaBJICvF/KSaVtCBgHcCHZwCKiEwSrSlkkglUmzUQtXW6RTsDGlDnWodtbVFIEom4Agh5UfdOmAIv0pHRXMXI5AgssYAyyJZ2BBJ0E1299M/7ln6cLl377N7n5P73JvXa+aZ+5zv+Z7zfM5zz/c5z7733HOquwMAAAAAAGPZttEFAAAAAACwtQmiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBR7djoAlZy1lln9QUXXLDRZQAAAAAAcBx79uz5QnfvWqvfXAbRF1xwQRYXFze6DAAAAAAAjqOqPjVNP5fmAAAAAABgVIJoAAAAAABGJYgGAAAAAGBUgmgAAAAAAEYliAYAAAAAYFSCaAAAAAAARrVmEF1V51bV+6vq41V1W1X99Ap9qqp+rar2VtVHqurJE/OurKpPDo8rZ70BAAAAAADMtx1T9Dmc5Ge7+8NV9Ygke6rq5u6+faLPc5JcODyekuQ1SZ5SVY9McnWShSQ9LLu7u++e6VZsNR+5MXn7TyQ5stGVAAAAAACrOfX05BWf3ugqNoU1z4ju7s9194eH519O8vEkZy/rdlmSN/aSDyU5o6oek+TZSW7u7oND+HxzkktnugVbzUduTN7+LyKEBgAAAIA5d+ie5D+ft9FVbAondI3oqrogyZOS/NGyWWcn+czE9L6hbbV2VvPeaza6AgAAAABgWofu2egKNoWpg+iqeniStyX5me7+6+WzV1ikj9O+0vqvqqrFqlo8cODAtGVtPffs2+gKAAAAAABmaqoguqp2ZimE/u3ufvsKXfYlOXdi+pwk+4/T/nW6+9ruXujuhV27dk1T1tZ0+jkbXQEAAAAAwEytGURXVSV5fZKPd/evrNJtd5IX1ZKnJrmnuz+X5KYkl1TVmVV1ZpJLhjZW8z2v3OgKAAAAAIBpnXr6RlewKeyYos/TkvxIko9W1a1D288lOS9Juvu1Sd6Z5LlJ9ib5SpIXD/MOVtWrktwyLHdNdx+cXflb0BN+aOnn238iblgIAAAAAHPs1NOTV3x6o6vYFKp7xUs2b6iFhYVeXFzc6DIAAAAAADiOqtrT3Qtr9Zv6ZoUAAAAAAHAyBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKh2rNWhqq5L8n1J7uru71hh/r9N8sKJ9T0uya7uPlhVdyb5cpIjSQ5398KsCgcAAAAAYHOY5ozo65NcutrM7v6l7r6ouy9K8ook/6e7D050eeYwXwgNAAAAAPAQtGYQ3d0fTHJwrX6DK5K8eV0VAQAAAACwpczsGtFV9Y1ZOnP6bRPNneTdVbWnqq6a1WsBAAAAALB5rHmN6BPw/Ul+f9llOZ7W3fur6puS3FxVfzacYf11hqD6qiQ577zzZlgWAAAAAAAbaWZnRCe5PMsuy9Hd+4efdyV5R5KLV1u4u6/t7oXuXti1a9cMywIAAAAAYCPNJIiuqtOTPD3J70y0PayqHnHseZJLknxsFq8HAAAAAMDmsealOarqzUmekeSsqtqX5OokO5Oku187dPvBJO/u7vsmFn10kndU1bHXeVN3/97sSgcAAAAAYDNYM4ju7ium6HN9kuuXtd2R5IknWxgAAAAAAFvDLK8RDQAAAAAAX0cQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCo1gyiq+q6qrqrqj62yvxnVNU9VXXr8HjlxLxLq+oTVbW3ql4+y8IBAAAAANgcpjkj+vokl67R5/9290XD45okqartSV6d5DlJHp/kiqp6/HqKBQAAAABg81kziO7uDyY5eBLrvjjJ3u6+o7vvT3JDkstOYj0AAAAAAGxis7pG9D+sqj+tqndV1bcPbWcn+cxEn31D24qq6qqqWqyqxQMHDsyoLAAAAAAANtosgugPJzm/u5+Y5L8n+V9De63Qt1dbSXdf290L3b2wa9euGZQFAAAAAMA8WHcQ3d1/3d33Ds/fmWRnVZ2VpTOgz53oek6S/et9PQAAAAAANpd1B9FV9XerqobnFw/r/GKSW5JcWFWPrapTklyeZPd6Xw8AAAAAgM1lx1odqurNSZ6R5Kyq2pfk6iQ7k6S7X5vk+Ul+sqoOJ/mbJJd3dyc5XFUvS3JTku1Jruvu20bZCgAAAAAA5lYtZcbzZWFhoRcXFze6DAAAAAAAjqOq9nT3wlr9ZnGzQgAAAAAAWJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUQmiAQAAAAAY1ZpBdFVdV1V3VdXHVpn/wqr6yPD4g6p64sS8O6vqo1V1a1UtzrJwAAAAAAA2h2nOiL4+yaXHmf+XSZ7e3U9I8qok1y6b/8zuvqi7F06uRAAAAAAANrMda3Xo7g9W1QXHmf8HE5MfSnLO+ssCAAAAAGCrmPU1ol+S5F0T053k3VW1p6qumvFrAQAAAACwCax5RvS0quqZWQqiv2ui+Wndvb+qvinJzVX1Z939wVWWvyrJVUly3nnnzaosAAAAAAA22EzOiK6qJyT5zSSXdfcXj7V39/7h511J3pHk4tXW0d3XdvdCdy/s2rVrFmUBAAAAADAH1h1EV9V5Sd6e5Ee6+88n2h9WVY849jzJJUk+tt7XAwAAAABgc1nz0hxV9eYkz0hyVlXtS3J1kp1J0t2vTfLKJI9K8utVlSSHu3shyaOTvGNo25HkTd39eyNsAwAAAAAAc2zNILq7r1hj/o8l+bEV2u9I8sSTLw0AAAAAgK1gJteIBgAAAACA1QiiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBRTRVEV9V1VXVXVX1slflVVb9WVXur6iNV9eSJeVdW1SeHx5WzKhwAAAAAgM1hx5T9rk/yP5K8cZX5z0ly4fB4SpLXJHlKVT0yydVJFpJ0kj1Vtbu7715P0Vvdjdf9cr7/zp/PaXVkxfmHsjOn5IEczbZsz9EV+3SSGqG25eu9L6fm/uzMGbn3pF/vSJb+R2SMepPZvRd35+H5fJ+eb6vPzmBts7Oe7fvb3r7qfnYiHsi27FxlX3ywjbXvH88D2ZajqZya6d7LMWucdt0PpLIjva461rsdR1PZll51/qHsSNJTv6/rsd5tmcVn4UY5ksr24/wexnLsFWtZ20rv37S/n7WOJ53kcCo7h1dfqYYH2zzUwJKt8rs4lB35Sk7LGbk3+/usvPfoRXnhtvdk+0ls2H05LW878l25Ytt7s7Om/5zYiGPxiTiaB+fPQiffh0PZkW058tXPn3l1Isfe+3JqduTwzI7TY47Bed8nVzNt3YeyM2858vR837YP5ZF17wktO2Zds152Gvfl1CTJw3JoxFc5Ocv38WPvxRifSQ9kW+7NN+aM3Jv7+tQ8rA5N9Z1rFo6m8ld9er65vrSu9axW46zWPwtf+zm/PafkyNx+1kzzO99Mn5XzVOvRqtx5/gvyLS9+3UaXsilU93RfhqrqgiS/293fscK81yX5QHe/eZj+RJJnHHt094+v1G81CwsLvbi4OPVGbCU3XvfL+cefuiY75mVE8TW6k/K7AQA2ifV+d/HdBzYHY5V5Mvb+aH9n3nQnd1xw+UM6jK6qPd29sFa/Wf3H29lJPjMxvW9oW62dVTztU78uhJ5jDnYAwGay3u8uvvvA5mCsMk/G3h/t78ybquT8T9240WVsCrMKok/kL2lXPAW7qq6qqsWqWjxw4MCMytp8HpMvbHQJAAAAAMCUtvd8XK503s0qiN6X5NyJ6XOS7D9O+9fp7mu7e6G7F3bt2jWjsjafz+WsjS4BAAAAAJjSkXow7kCx+c3qXdqd5EW15KlJ7unuzyW5KcklVXVmVZ2Z5JKhjVX8/vn/Mofn+x4mD2lTXlIdAGAurPe7i+8+sDkYq8yTsfdH+zvzpjv51Pk/tNFlbAo7pulUVW/O0o0Hz6qqfUmuTrIzSbr7tUnemeS5SfYm+UqSFw/zDlbVq5LcMqzqmu4+OMsN2Gp+6J//bG68Lvn+O38+p9XKd6A+lJ05JQ/kaLZle1Y+9X+sO4guX+99OTX3Z2fOyL0n/XpHsvQ/IvN4V+dJd+fh+Xyfnm/LZ2ewttlZz/b9bW9fdT87EQ9kW3ausi8+2Dbi7rkPZFuOpqa+a/w83MX8gVR2pNdVx3q342gq21a+WlOS5FB2JOmp39f1WO+2zOKzcKMcSWX7cX4PY1l+5/hjbSdyra/l1jqedJLDqewcXn2lGh5s81ADS7bK7+JQduQrOS1n5L7s70flvUcvygu3vSfbT2LD7stpeduR78oV296bnTX958Q83cl+JUczu7NxjmfyfTiUHdmWI1/9/JlXJ3LsvS+nZkcOz+w4PeYYnPd9cjXT1n0oO/OWI0/P9237UB5Z957QsmPWNetlp3FfTk2SPCyHRnyVk7N8Hz/2XozxmfRAtuXefGPOyH25r0/Jw+rQVN+5ZuFoKn/Vp+eb86V1rWe1Gme1/ln42s/57TklR+b2s2aa3/lm+qycp1qPVuXOC17wkL5R4YmonsP/SlpYWOjFxcWNLgMAAAAAgOOoqj3dvbBWPxcwAQAAAABgVIJoAAAAAABGJYgGAAAAAGBUgmgAAAAAAEYliAYAAAAAYFSCaAAAAAAARiWIBgAAAABgVIJoAAAAAABGJYgGAAAAAGBUgmgAAAAAAEYliAYAAAAAYFSCaAAAAAAARiWIBgAAAABgVIJoAAAAAABGJYgGAAAAAGBUgmgAAAAAAEY1VRBdVZdW1Seqam9VvXyF+b9aVbcOjz+vqi9NzDsyMW/3LIsHAAAAAGD+7VirQ1VtT/LqJM9Ksi/JLVW1u7tvP9anu//1RP9/leRJE6v4m+6+aHYlAwAAAACwmUxzRvTFSfZ29x3dfX+SG5Jcdpz+VyR58yyKAwAAAABg85smiD47yWcmpvcNbV+nqs5P8tgk75toPq2qFqvqQ1X1A6u9SFVdNfRbPHDgwBRlAQAAAACwGUwTRNcKbb1K38uTvLW7j0y0ndfdC0l+OMl/rapvWWnB7r62uxe6e2HXrl1TlAUAAAAAwGYwTRC9L8m5E9PnJNm/St/Ls+yyHN29f/h5R5IP5GuvHw0AAAAAwBY3TRB9S5ILq+qxVXVKlsLm3cs7VdU/SHJmkj+caDuzqk4dnp+V5GlJbl++LAAAAAAAW9eOtTp09+GqelmSm5JsT3Jdd99WVdckWezuY6H0FUlu6O7Jy3Y8LsnrqupolkLvX+huQTQAAAAAwENIfW1uPB8WFhZ6cXFxo8sAAAAAAOA4qmrPcI/A45rm0hwAAAAAAHDSBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKimCqKr6tKq+kRV7a2ql68w/0er6kBV3To8fmxi3pVV9cnhceUsiwcAAAAAYP7tWKtDVW1P8uokz0qyL8ktVbW7u29f1vUt3f2yZcs+MsnVSRaSdJI9w7J3z6R6AAAAAADm3jRnRF+cZG9339Hd9ye5IcllU67/2Ulu7u6DQ/h8c5JLT65UAAAAAAA2o2mC6LOTfGZiet/Qttw/qaqPVNVbq+rcE1wWAAAAAIAtapogulZo62XT/zvJBd39hCTvSfKGE1h2qWPVVVW1WFWLBw4cmKIsAAAAAAA2g2mC6H1Jzp2YPifJ/skO3f3F7j40TP5Gku+cdtmJdVzb3QvdvbBr165pagcAAAAAYBOYJoi+JcmFVfXYqjolyeVJdk92qKrHTEw+L8nHh+c3Jbmkqs6sqjOTXDK0AQAAAADwELFjrQ7dfbiqXpalAHl7kuu6+7aquibJYnfvTvJTVfW8JIeTHEzyo8OyB6vqVVkKs5Pkmu4+OMJ2AAAAAAAwp6p7xUs2b6iFhYVeXFzc6DIAAAAAADiOqtrT3Qtr9Zvm0hwAAAAAAHDSBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqATRAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKimCqKr6tKq+kRV7a2ql68w/99U1e1V9ZGqem9VnT8x70hV3To8ds+yeAAAAAAA5t+OtTpU1fYkr07yrCT7ktxSVbu7+/aJbn+SZKG7v1JVP5nkvyR5wTDvb7r7ohnXDQAAAADAJjHNGdEXJ9nb3Xd09/1Jbkhy2WSH7n5/d39lmPxQknNmWyYAAAAAAJvVNEH02Uk+MzG9b2hbzUuSvGti+rSqWqyqD1XVD5xEjQAAAAAAbGJrXpojSa3Q1it2rPpnSRaSPH2i+bzu3l9Vfy/J+6rqo939Fysse1WSq5LkvPPOm6IsAAAAAAA2g2nOiN6X5NyJ6XOS7F/eqaq+N8m/T/K87j50rL279w8/70jygSRPWulFuvva7l7o7oVdu3ZNvQEAAAAAAMy3aYLoW5JcWFWPrapTklyeZPdkh6p6UpLXZSmEvmui/cyqOnV4flaSpyWZvMkhAAAAAABb3JqX5ujuw1X1siQ3Jdme5Lruvq2qrkmy2N27k/xSkocn+Z9VlSSf7u7nJXlcktdV1dEshd6/0N2CaAAAAACAh5DqXvFyzxtqYWGhFxcXN7oMAAAAAACOo6r2dPfCWv2muTQHAAAAAACcNEE0AAAAAACjEkQDAAAAADAqQTQAAAAAAKMSRAMAAAAAMCpBNAAAAAAAoxJEAwAAAAAwKkE0AAAAAACjEkQDAAAAADAqQTQAAAAAAKMSRAMAAAAAMCpBNAAAAAAAoxJEAwAAAAAwKkE0AAAAAACjEkQDAAAAADAqQTQAAAAAAKPaMU2nqro0yX9Lsj3Jb3b3Lyybf2qSNyb5ziRfTPKC7r5zmPeKJC9JciTJT3X3TTOrfos68srTs602ugoAAAAA4Hge6OSUa+7Z6DI2hTWD6KranuTVSZ6VZF+SW6pqd3ffPtHtJUnu7u5vrarLk/xikhdU1eOTXJ7k25N8c5L3VNXf7+4js96QreJYCF2CaAAAAACYazuT3P/K04XRU5jm0hwXJ9nb3Xd09/1Jbkhy2bI+lyV5w/D8rUm+p6pqaL+huw91918m2Tusj1UIoQEAAABgc6hKdsrypjJNEH12ks9MTO8b2lbs092Hk9yT5FFTLpskqaqrqmqxqhYPHDgwXfUAAAAAAMy9aYLolTL9nrLPNMsuNXZf290L3b2wa9euKcoCAAAAAGAzmCaI3pfk3Inpc5LsX61PVe1IcnqSg1Muy4SjnfSKUT0AAAAAME+6l25YyNrWvFlhkluSXFhVj03y2SzdfPCHl/XZneTKJH+Y5PlJ3tfdXVW7k7ypqn4lSzcrvDDJH8+q+K1o+zX3LN2wcKMLAQAAAACO64GOGxVOac0gursPV9XLktyUZHuS67r7tqq6Jslid+9O8vokv1VVe7N0JvTlw7K3VdWNSW5PcjjJS7v7yEjbsmVst/MCAAAAwNw7ZaML2ESq5/A6EAsLC724uLjRZQAAAAAAcBxVtae7F9bq5woQAAAAAACMShANAAAAAMCoBNEAAAAAAIxKEA0AAAAAwKgE0QAAAAAAjEoQDQAAAADAqKq7N7qGr1NVB5J8aqPrmANnJfnCRhcBm5xxBLNhLMH6GUewfsYRzIaxBOtnHP1/53f3rrU6zWUQzZKqWuzuhY2uAzYz4whmw1iC9TOOYP2MI5gNYwnWzzg6cS7NAQAAAADAqATRAAAAAACMShA9367d6AJgCzCOYDaMJVg/4wjWzziC2TCWYP2MoxPkGtEAAAAAAIzKGdEAAAAAAIxKED2HqurSqvpEVe2tqpdvdD0wj6rqzqr6aFXdWlWLQ9sjq+rmqvrk8PPMob2q6teGMfWRqnryxHquHPp/sqqu3KjtgQdDVV1XVXdV1ccm2mY2bqrqO4dxuXdYth7cLYTxrTKO/kNVfXY4Jt1aVc+dmPeKYUx8oqqePdG+4ve9qnpsVf3RML7eUlWnPHhbBw+eqjq3qt5fVR+vqtuq6qeHdsclmNJxxpHjEkypqk6rqj+uqj8dxtF/HNpX3Per6tRheu8w/4KJdZ3Q+HooEkTPmaranuTVSZ6T5PFJrqiqx29sVTC3ntndF3X3wjD98iTv7e4Lk7x3mE6WxtOFw+OqJK9Jlv6hk+TqJE9JcnGSq4/9Ywe2qOuTXLqsbZbj5jVD32PLLX8t2Aquz8r79q8Ox6SLuvudSTJ8h7s8ybcPy/x6VW1f4/veLw7rujDJ3UleMurWwMY5nORnu/txSZ6a5KXDOHBcgumtNo4SxyWY1qEk393dT0xyUZJLq+qpWX3ff0mSu7v7W5P86tDvZMfXQ44gev5cnGRvd9/R3fcnuSHJZRtcE2wWlyV5w/D8DUl+YKL9jb3kQ0nOqKrHJHl2kpu7+2B3353k5vgHCltYd38wycFlzTMZN8O8v9Pdf9hLN6B448S6YMtYZRyt5rIkN3T3oe7+yyR7s/Rdb8Xve8PZmt+d5K3D8pNjEraU7v5cd394eP7lJB9PcnYcl2BqxxlHq3FcgmWG48q9w+TO4dFZfd+fPE69Ncn3DGPlhMbXyJs1twTR8+fsJJ+ZmN6X4x9I4KGqk7y7qvZU1VVD26O7+3PJ0peyJN80tK82row3mN24OXt4vrwdHipeNlwu4LqJszFPdBw9KsmXuvvwsnbY0oY/a35Skj+K4xKclGXjKHFcgqkNZy7fmuSuLP2H5l9k9X3/q+NlmH9PlsaK3GEKguj5s9J1y/pBrwLm39O6+8lZ+vOWl1bVPzpO39XGlfEGqzvRcWM88VD2miTfkqU/5/xckl8e2o0jWENVPTzJ25L8THf/9fG6rtBmPEFWHEeOS3ACuvtId1+U5JwsncH8uJW6DT+No3UQRM+ffUnOnZg+J8n+DaoF5lZ37x9+3pXkHVk6WHx++DPMDD/vGrqvNq6MN5jduNk3PF/eDlted39++AfM0SS/kaVjUnLi4+gLWbrcwI5l7bAlVdXOLIVnv93dbx+aHZfgBKw0jhyX4OR095eSfCBL11xfbd//6ngZ5p+epcu2yR2mIIieP7ckuXC4O+cpWbrQ+e4NrgnmSlU9rKoecex5kkuSfCxLY+XYndKvTPI7w/PdSV5US56a5J7hTz1vSnJJVZ05/LnaJUMbPJTMZNwM875cVU8drpH2ool1wZZ2LDQb/GCWjknJ0ji6fLi7+mOzdLO0P84q3/eG69i+P8nzh+UnxyRsKcOx4vVJPt7dvzIxy3EJprTaOHJcgulV1a6qOmN4/g1JvjdL11tfbd+fPE49P8n7hrFyQuNr/C2bTzvW7sKDqbsPV9XLsvSFanuS67r7tg0uC+bNo5O8Y+l7V3YkeVN3/15V3ZLkxqp6SZJPJ/mnQ/93Jnlulm4W8JUkL06S7j5YVa/K0oEhSa7p7mlvQAWbTlW9OckzkpxVVfuSXJ3kFzK7cfOTSa5P8g1J3jU8YEtZZRw9o6ouytKfWd6Z5MeTpLtvq6obk9ye5HCSl3b3kWE9q33f+3dJbqiq/5TkT7IUMMBW9LQkP5Lko8N1OZPk5+K4BCditXF0heMSTO0xSd5QVduzdMLujd39u1V1e1be91+f5Leqam+WzoS+PDnp8fWQU0uhPQAAAAAAjMOlOQAAAAAAGJUgGgAAAACAUQmiAQAAAAAYlSAaAAAAAIBRCaIBAAAAABiVIBoAAAAAgFEJogEAAAAAGJUgGgAAAACAUf0/CLVHd4S19zkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1800x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,4))\n",
    "plt.scatter(range(30000),label[:30000])\n",
    "plt.scatter(range(30000),train.feature_13[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['feature_11'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mean']=np.mean(train.iloc[:,0:6],axis=1)\n",
    "test['Mean']=np.mean(test.iloc[:,0:6],axis=1)\n",
    "train['Median']=np.median(train.iloc[:,0:6],axis=1)\n",
    "test['Median']=np.median(test.iloc[:,0:6],axis=1)\n",
    "train['Std']=np.std(train.iloc[:,0:6],axis=1)\n",
    "test['Std']=np.std(test.iloc[:,0:6],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mean1']=np.mean(train.iloc[:,7:],axis=1)\n",
    "test['Mean1']=np.mean(test.iloc[:,7:],axis=1)\n",
    "train['Median1']=np.median(train.iloc[:,7:],axis=1)\n",
    "test['Median1']=np.median(test.iloc[:,7:],axis=1)\n",
    "train['Std1']=np.std(train.iloc[:,7:],axis=1)\n",
    "test['Std1']=np.std(test.iloc[:,7:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33293\n",
       "1      615\n",
       "Name: feature_10, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['feature_10'].value_counts()         #4, 6,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "mm=MinMaxScaler()\n",
    "#tr=pd.DataFrame(mm.fit_transform(train[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "#te=pd.DataFrame(mm.fit_transform(test[['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1']]))\n",
    "\n",
    "train=pd.DataFrame(mm.fit_transform(train))\n",
    "test=pd.DataFrame(mm.fit_transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=pd.concat([train,tr],axis=1)\n",
    "#test=pd.concat([test,te],axis=1)\n",
    "#train.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)\n",
    "#test.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_14','Mean','Median','Std','Mean1','Median1','Std1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.272422</td>\n",
       "      <td>-0.421012</td>\n",
       "      <td>1.344057</td>\n",
       "      <td>-0.012199</td>\n",
       "      <td>0.076245</td>\n",
       "      <td>1.08786</td>\n",
       "      <td>1.491578</td>\n",
       "      <td>0.737099</td>\n",
       "      <td>0.732879</td>\n",
       "      <td>-0.218297</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>-1.294893</td>\n",
       "      <td>1.027791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857936</td>\n",
       "      <td>0.146322</td>\n",
       "      <td>0.503673</td>\n",
       "      <td>-0.976688</td>\n",
       "      <td>-0.566950</td>\n",
       "      <td>-0.40927</td>\n",
       "      <td>-1.838207</td>\n",
       "      <td>-0.182990</td>\n",
       "      <td>0.208051</td>\n",
       "      <td>-0.290707</td>\n",
       "      <td>-1.099160</td>\n",
       "      <td>-0.408399</td>\n",
       "      <td>-1.280393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952132</td>\n",
       "      <td>-0.173937</td>\n",
       "      <td>1.824277</td>\n",
       "      <td>-0.701673</td>\n",
       "      <td>0.076245</td>\n",
       "      <td>-0.40927</td>\n",
       "      <td>-0.173314</td>\n",
       "      <td>0.645013</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>0.187611</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>0.202256</td>\n",
       "      <td>-0.153707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857936</td>\n",
       "      <td>-0.378592</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>-0.039313</td>\n",
       "      <td>-0.566950</td>\n",
       "      <td>-0.40927</td>\n",
       "      <td>-0.173314</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>-0.322589</td>\n",
       "      <td>-0.265020</td>\n",
       "      <td>-0.449102</td>\n",
       "      <td>-0.616166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.328918</td>\n",
       "      <td>1.565628</td>\n",
       "      <td>-1.177096</td>\n",
       "      <td>-0.097415</td>\n",
       "      <td>-0.245352</td>\n",
       "      <td>-0.40927</td>\n",
       "      <td>0.825621</td>\n",
       "      <td>0.406403</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.414804</td>\n",
       "      <td>-0.576237</td>\n",
       "      <td>-1.646107</td>\n",
       "      <td>0.209970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4        5         6   \\\n",
       "0 -0.272422 -0.421012  1.344057 -0.012199  0.076245  1.08786  1.491578   \n",
       "1  0.857936  0.146322  0.503673 -0.976688 -0.566950 -0.40927 -1.838207   \n",
       "2  0.952132 -0.173937  1.824277 -0.701673  0.076245 -0.40927 -0.173314   \n",
       "3  0.857936 -0.378592  0.983892 -0.039313 -0.566950 -0.40927 -0.173314   \n",
       "4  1.328918  1.565628 -1.177096 -0.097415 -0.245352 -0.40927  0.825621   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0  0.737099  0.732879 -0.218297  0.047431 -1.294893  1.027791  \n",
       "1 -0.182990  0.208051 -0.290707 -1.099160 -0.408399 -1.280393  \n",
       "2  0.645013  0.471525  0.187611  0.269656  0.202256 -0.153707  \n",
       "3  0.182364 -0.051453 -0.322589 -0.265020 -0.449102 -0.616166  \n",
       "4  0.406403  0.072464  0.414804 -0.576237 -1.646107  0.209970  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.073439</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.174269</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.194658</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.049018</td>\n",
       "      <td>0.411869</td>\n",
       "      <td>0.102731</td>\n",
       "      <td>0.651687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.089345</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138673</td>\n",
       "      <td>0.245842</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.256009</td>\n",
       "      <td>0.219509</td>\n",
       "      <td>0.253043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189055</td>\n",
       "      <td>0.275214</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.442077</td>\n",
       "      <td>0.299950</td>\n",
       "      <td>0.447631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.074628</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.050427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160904</td>\n",
       "      <td>0.216912</td>\n",
       "      <td>0.044942</td>\n",
       "      <td>0.369396</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.367761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.129138</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174536</td>\n",
       "      <td>0.230726</td>\n",
       "      <td>0.073757</td>\n",
       "      <td>0.327091</td>\n",
       "      <td>0.056466</td>\n",
       "      <td>0.510442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.259740  0.073439  0.866667  0.051850  0.032258  0.174269  0.018182   \n",
       "1  0.415584  0.089345  0.633333  0.001220  0.000000  0.000000  0.000000   \n",
       "2  0.428571  0.080366  1.000000  0.015657  0.032258  0.000000  0.000000   \n",
       "3  0.415584  0.074628  0.766667  0.050427  0.000000  0.000000  0.000000   \n",
       "4  0.480519  0.129138  0.166667  0.047377  0.016129  0.000000  0.000000   \n",
       "\n",
       "         7    8         9   ...   12   13        14        15        16  \\\n",
       "0  0.272727  0.0  0.333333  ...  0.0  0.0  0.909091  0.666667  0.194658   \n",
       "1  0.363636  0.5  0.666667  ...  0.0  0.0  0.000000  1.000000  0.138673   \n",
       "2  0.545455  0.5  0.666667  ...  0.0  0.0  0.454545  1.000000  0.189055   \n",
       "3  0.363636  0.0  0.666667  ...  0.0  0.0  0.454545  1.000000  0.160904   \n",
       "4  0.000000  0.5  0.333333  ...  0.0  0.0  0.727273  1.000000  0.174536   \n",
       "\n",
       "         17        18        19        20        21  \n",
       "0  0.304350  0.049018  0.411869  0.102731  0.651687  \n",
       "1  0.245842  0.046188  0.256009  0.219509  0.253043  \n",
       "2  0.275214  0.064879  0.442077  0.299950  0.447631  \n",
       "3  0.216912  0.044942  0.369396  0.214147  0.367761  \n",
       "4  0.230726  0.073757  0.327091  0.056466  0.510442  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=pd.get_dummies((train[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "#b=pd.get_dummies((test[['feature_7','feature_8','feature_9','feature_13','feature_15']]).astype('category'))\n",
    "\n",
    "a=pd.get_dummies((train[[7,8,9,13,15]]).astype('category'))\n",
    "b=pd.get_dummies((test[[7,8,9,13,15]]).astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([train,a],axis=1)\n",
    "test=pd.concat([test,b],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11303, 48)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=[7,8,9,13,15],inplace=True)\n",
    "test.drop(columns=[7,8,9,13,15],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(m, train= train, label = label, test = test, random_state = 9):\n",
    "    a = list()\n",
    "    b = list()\n",
    "    sss=StratifiedShuffleSplit(random_state= random_state,test_size=0.2,n_splits=5)\n",
    "    for tr_index, te_index in sss.split(train,label):\n",
    "        xtrain, xtest = train.loc[tr_index,:], train.loc[te_index,:]\n",
    "        ytrain, ytest = label[tr_index], label[te_index]   \n",
    "        m.fit(xtrain,ytrain)\n",
    "        p = m.predict(xtest)\n",
    "        a.append(accuracy_score(ytest,p))\n",
    "        b.append(f1_score(ytest,p))\n",
    "    #print(pd.Series(m.feature_importances_, index = train.columns).sort_values(ascending=True).plot.barh())\n",
    "    print(np.mean(a),'    ',np.mean(b))\n",
    "  #  return(pd.DataFrame(m.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8994986729578296      0.41555908152531185\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8703332350339134      0.456580437565829\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8974048953111178      0.42773925400341284\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8980831613093482      0.4592901591493514\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.9036862282512533      0.4937719355267691\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8941610144500147      0.37882387947391083\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "l=[LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier()]\n",
    "n=0\n",
    "while(n<=(len(l)-1)):\n",
    "    splitting(l[n],train,label,test,random_state=2500)\n",
    "    print(l[n])\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9055440872898851      0.5025970122273735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "splitting(GradientBoostingClassifier(),train,label,test,random_state=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
